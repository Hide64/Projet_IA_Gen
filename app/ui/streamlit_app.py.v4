# -*- coding: utf-8 -*-
import os
import requests
import streamlit as st
import psycopg2
import pandas as pd
import numpy as np
import json, requests
from psycopg2.extras import RealDictCursor

# ===============================
# PostgreSQL config
# ===============================
PG_HOST = os.getenv("POSTGRES_HOST", "postgres")
PG_DB   = os.getenv("POSTGRES_DB", "videotheque")
PG_USER = os.getenv("POSTGRES_USER", "postgres")
PG_PWD  = os.getenv("POSTGRES_PASSWORD", "postgres")
PG_PORT = int(os.getenv("POSTGRES_PORT", "5432"))

DEFAULT_USER_ID = int(os.getenv("APP_USER_ID", "1"))

# ===============================
# DB helpers
# ===============================
def get_conn():
    return psycopg2.connect(
        host=PG_HOST,
        dbname=PG_DB,
        user=PG_USER,
        password=PG_PWD,
        port=PG_PORT,
        options="-c client_encoding=UTF8",
    )

def fetch_df(conn, sql, params=None):
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        cur.execute(sql, params or {})
        return pd.DataFrame(cur.fetchall())

# ===============================
# SQL
# ===============================

# Profil genre: moyenne de tes notes pour les films SEEN ayant ce genre
SQL_GENRE_PROFILE = """
WITH rated_seen AS (
  SELECT film_id, rating_10
  FROM user_film
  WHERE user_id = %(user_id)s
    AND status = 'SEEN'
    AND rating_10 IS NOT NULL
)
SELECT fg.genre_id,
       AVG(rs.rating_10) AS avg_rating,
       COUNT(*)          AS n
FROM rated_seen rs
JOIN film_genre fg ON fg.film_id = rs.film_id
GROUP BY fg.genre_id
HAVING COUNT(*) >= 2;
"""

# Candidats: films dispo (film_source) et non vus
# + filtre ASCII pour √©viter titres non localis√©s en asiatique (retire la ligne si tu veux)
SQL_CANDIDATES = """
SELECT DISTINCT
  f.film_id,
  f.title,
  f.year,
  f.runtime_min
FROM film f
JOIN film_source fs ON fs.film_id = f.film_id
LEFT JOIN user_film uf
  ON uf.user_id = %(user_id)s AND uf.film_id = f.film_id
WHERE COALESCE(uf.status::text, 'WANT') <> 'SEEN'
  AND f.title ~ '^[\\x00-\\x7F]+$';
"""

SQL_FILM_GENRES = "SELECT film_id, genre_id FROM film_genre;"
SQL_GENRES      = "SELECT genre_id, name FROM genre;"

# R√©alisateurs par film (√† adapter si ton sch√©ma diff√®re)
SQL_FILM_DIRECTORS = """
SELECT
  fc.film_id,
  STRING_AGG(p.name, ', ' ORDER BY p.name) AS directors
FROM film_credit fc
JOIN person p ON p.person_id = fc.person_id
WHERE
  fc.department = 'Directing'
  AND fc.job = 'Director'
GROUP BY fc.film_id;
"""

# Profil r√©alisateur: moyenne de tes notes sur les films vus de ce r√©alisateur
SQL_DIRECTOR_PROFILE = """
WITH rated_seen AS (
  SELECT film_id, rating_10
  FROM user_film
  WHERE user_id = %(user_id)s
    AND status = 'SEEN'
    AND rating_10 IS NOT NULL
),
directors AS (
  SELECT fc.film_id, p.name AS director_name
  FROM film_credit fc
  JOIN person p ON p.person_id = fc.person_id
  WHERE
    fc.department = 'Directing'
    AND fc.job = 'Director'
)
SELECT
  d.director_name,
  AVG(rs.rating_10) AS avg_rating,
  COUNT(*)          AS n
FROM rated_seen rs
JOIN directors d ON d.film_id = rs.film_id
GROUP BY d.director_name
HAVING COUNT(*) >= 2
ORDER BY avg_rating DESC;
"""

# ===============================
# Scoring + explanation
# ===============================
def recommend(candidates, film_genres, genre_profile, genre_names,
              film_directors, director_profile,
              max_runtime, top_k):

    def director_best(directors_str: str):
        """Retourne (best_dir, best_avg, best_n) ou (None,None,None)"""
        if not directors_str:
            return None, None, None

        directors = [d.strip() for d in directors_str.split(",") if d.strip()]
        best_dir = None
        best_avg = None
        best_n = None

        for d in directors:
            info = director_profile.get(d)  # (avg, n)
            if info is None:
                continue
            avg, n = info
            if best_avg is None or avg > best_avg:
                best_dir, best_avg, best_n = d, float(avg), int(n)

        return best_dir, best_avg, best_n

    rows = []
    raw_scores = []

    # 1) calcul des scores bruts (sans clamp)
    for _, f in candidates.iterrows():
        genres = film_genres.get(f.film_id, [])
        if not genres:
            continue

        vals = [float(genre_profile.get(g, 0.0)) for g in genres]
        s_genre = float(np.mean(vals)) if vals else 0.0

        directors_str = film_directors.get(f.film_id)
        best_dir, best_dir_score, best_dir_n = director_best(directors_str)

        s_dir = float(best_dir_score) if best_dir_score is not None else s_genre
        bonus_runtime = 0.15 if (f.runtime_min is not None and f.runtime_min <= max_runtime) else 0.0

        raw = 0.85 * s_genre + 0.15 * s_dir + bonus_runtime  # pas de clamp ici

        # explication
        top_genres = sorted(
            [(g, float(genre_profile.get(g, 0.0))) for g in genres],
            key=lambda x: x[1],
            reverse=True
        )[:2]

        why_lines = []
        why_lines.append("‚Ä¢ Genres : " + ", ".join(
            f"{genre_names.get(g, '?')} ({w:.1f}/10)" for g, w in top_genres
        ))

        if best_dir:
            why_lines.append(
                f"‚Ä¢ R√©alisateur : {best_dir} (moyenne {best_dir_score:.1f}/10 sur {best_dir_n} films vus)"
            )
        elif directors_str:
            why_lines.append(f"‚Ä¢ R√©alisateur : {directors_str}")

        if bonus_runtime > 0:
            why_lines.append(f"‚Ä¢ Dur√©e : ‚â§ {max_runtime} min (bonus)")

        rows.append({
            "film_id": f.film_id,
            "title": f.title,
            "year": f.year,
            "runtime": f.runtime_min,
            "raw_score": float(raw),
            "why": "\n".join(why_lines)
        })
        raw_scores.append(float(raw))

    if not rows:
        return pd.DataFrame()

    df = pd.DataFrame(rows)

    # 2) normalisation min-max -> score entre 6.0 et 10.0 (modifiable)
    min_raw = float(df["raw_score"].min())
    max_raw = float(df["raw_score"].max())

    if max_raw - min_raw < 1e-9:
        # tous les raw sont identiques: on √©vite "tout √† 10"
        df["score"] = 8.0
    else:
        df["score"] = 6.0 + 4.0 * (df["raw_score"] - min_raw) / (max_raw - min_raw)

    df["score"] = df["score"].clip(0.0, 10.0).round(2)

    # 3) tri et top_k
    df = df.sort_values("score", ascending=False).head(top_k)

    # on garde ce que l'IHM utilise
    return df[["film_id", "title", "year", "runtime", "score", "why"]]

# ===============================
# Appel Ollama
# ===============================
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama:11434")

@st.cache_data(show_spinner=False, ttl=3600)
def ollama_rewrite(model: str, title: str, year, score: float, why: str) -> str:
    """
    Reformule une recommandation en FR, sans inventer.
    Cache 1h pour √©viter de relancer √† chaque rerun Streamlit.
    """
    prompt = f"""
Tu es un assistant cin√©ma. Reformule en fran√ßais, en 2 √† 4 phrases maximum, sans inventer de faits.

Film : {title} ({year})
Score : {score}/10
Raisons (faits bruts) :
{why}

Contraintes :
- Ne mentionne pas "base de donn√©es" ou "algorithme".
- N'invente pas de casting, de synopsis, de prix ou de r√©compenses.
- Style clair et naturel, ton conseiller perso.
"""

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "Tu es un assistant cin√©ma concis et fiable. Tu ne dois jamais inventer des faits."},
            {"role": "user", "content": prompt.strip()}
        ],
        "stream": False,
        "options": {
            "temperature": 0.4,
            "num_predict": 160
        }
    }

    try:
        r = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=30)
        r.raise_for_status()
        data = r.json()
        return (data.get("message", {}) or {}).get("content", "").strip() or "‚Äî"
    except Exception as e:
        # On ne bloque pas l'app si le LLM a un souci
        return f"(LLM indisponible: {e})"

@st.cache_data(show_spinner=False, ttl=300)
def load_data(user_id: int):
    conn = get_conn()

    genre_profile_df = fetch_df(conn, SQL_GENRE_PROFILE, {"user_id": user_id})
    candidates = fetch_df(conn, SQL_CANDIDATES, {"user_id": user_id})
    film_genres_df = fetch_df(conn, SQL_FILM_GENRES)
    genres_df = fetch_df(conn, SQL_GENRES)
    film_directors_df = fetch_df(conn, SQL_FILM_DIRECTORS)
    director_profile_df = fetch_df(conn, SQL_DIRECTOR_PROFILE, {"user_id": user_id})

    conn.close()

    # Maps
    genre_profile = {int(k): float(v) for k, v in zip(genre_profile_df.genre_id, genre_profile_df.avg_rating)}
    genre_names = dict(zip(genres_df.genre_id, genres_df.name))
    film_genres = film_genres_df.groupby("film_id")["genre_id"].apply(list).to_dict()

    film_directors = {}
    if not film_directors_df.empty:
        film_directors = dict(zip(film_directors_df["film_id"], film_directors_df["directors"]))

    director_profile = {}
    if not director_profile_df.empty:
        director_profile = {
            row["director_name"]: (float(row["avg_rating"]), int(row["n"]))
            for _, row in director_profile_df.iterrows()
        }

    return genre_profile_df, candidates, genre_profile, genre_names, film_genres, film_directors, director_profile, director_profile_df

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.1:8b")

@st.cache_data(show_spinner=False, ttl=3600)
def llm_extract_filters(user_text: str, available_genres: list[str]) -> dict:
    schema_hint = {
        "genres_include": [],
        "genres_exclude": [],
        "max_runtime": None,
        "year_min": None,
        "year_max": None,
        "director": None,
        "top_k": 10,
        "ascii_only": True
    }

    prompt = f"""
Tu extrais des contraintes de recommandation de films.
R√©ponds uniquement avec un JSON valide, sans texte autour.

Genres possibles (utilise uniquement ceux-ci) :
{available_genres}

Sch√©ma JSON attendu :
{json.dumps(schema_hint, ensure_ascii=False)}

R√®gles :
- Si une info n'est pas pr√©cis√©e, mets null (ou [] pour les listes).
- max_runtime entier (minutes), year_min/year_max entiers.
- top_k entre 3 et 15.
- ascii_only = true par d√©faut.
- N'invente pas de genres hors liste.

Demande utilisateur :
{user_text}
""".strip()

    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {"role": "system", "content": "Tu r√©ponds uniquement avec du JSON valide."},
            {"role": "user", "content": prompt}
        ],
        "stream": False,
        "options": {"temperature": 0.0, "num_predict": 220}
    }

    r = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=120)
    r.raise_for_status()
    content = (r.json().get("message", {}) or {}).get("content", "").strip()

    content = content.replace("```json", "").replace("```", "").strip()
    data = json.loads(content)

    data.setdefault("genres_include", [])
    data.setdefault("genres_exclude", [])
    data.setdefault("top_k", 10)
    data.setdefault("ascii_only", True)

    tk = int(data.get("top_k", 10))
    data["top_k"] = 10 if not (3 <= tk <= 15) else tk

    allowed = set(available_genres)
    data["genres_include"] = [g for g in data["genres_include"] if g in allowed]
    data["genres_exclude"] = [g for g in data["genres_exclude"] if g in allowed]

    return data

def apply_filters(candidates: pd.DataFrame,
                  film_genres: dict,
                  film_directors: dict,
                  filters: dict,
                  genre_id_by_name: dict) -> pd.DataFrame:

    df = candidates.copy()

    # ascii titles
    if filters.get("ascii_only", True):
        df = df[df["title"].str.match(r'^[\x00-\x7F]+$', na=False)]

    # year
    y_min = filters.get("year_min")
    y_max = filters.get("year_max")
    if y_min is not None:
        df = df[df["year"].fillna(0).astype(int) >= int(y_min)]
    if y_max is not None:
        df = df[df["year"].fillna(9999).astype(int) <= int(y_max)]

    # runtime
    max_rt = filters.get("max_runtime")
    if max_rt is not None:
        df = df[df["runtime_min"].fillna(10**9).astype(int) <= int(max_rt)]

    # director (simple contains)
    director = filters.get("director")
    if director:
        df = df[df["film_id"].map(lambda fid: (film_directors.get(fid) or "").lower()).str.contains(director.lower())]

    # genres include/exclude
    inc = filters.get("genres_include", [])
    exc = filters.get("genres_exclude", [])
    inc_ids = {genre_id_by_name[g] for g in inc if g in genre_id_by_name}
    exc_ids = {genre_id_by_name[g] for g in exc if g in genre_id_by_name}

    def has_all_included(fid: int) -> bool:
        gset = set(film_genres.get(fid, []))
        return inc_ids.issubset(gset) if inc_ids else True

    def has_any_excluded(fid: int) -> bool:
        gset = set(film_genres.get(fid, []))
        return bool(gset.intersection(exc_ids)) if exc_ids else False

    df = df[df["film_id"].map(has_all_included)]
    df = df[~df["film_id"].map(has_any_excluded)]

    return df

def llm_format_answer(user_text: str, recos_df: pd.DataFrame) -> str:
    """
    Met en forme en fran√ßais une r√©ponse courte √† partir des recos calcul√©es.
    IMPORTANT : le LLM ne doit pas inventer de faits.
    """
    recos_payload = []
    for r in recos_df.itertuples(index=False):
        recos_payload.append({
            "title": r.title,
            "year": int(r.year) if r.year is not None else None,
            "runtime": int(r.runtime) if r.runtime is not None else None,
            "score": float(r.score),
            "why": r.why
        })

    prompt = f"""
Tu es un assistant cin√©ma. Tu r√©ponds en fran√ßais.
Tu dois utiliser uniquement les informations fournies. N'invente rien (casting, synopsis, prix, etc.).

Demande utilisateur :
{user_text}

Recommandations (faits) :
{json.dumps(recos_payload, ensure_ascii=False)}

Consignes :
- Commence par 1 phrase qui r√©sume le choix global.
- Puis liste 3 √† 5 films max.
- Pour chaque film : 2 bullets max (bas√©s sur "why" + ann√©e/dur√©e/score).
- Termine par une question courte pour affiner (ex: plut√¥t plus court ? plus r√©cent ?).
""".strip()

    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {"role": "system", "content": "Assistant concis et fiable. Tu n'inventes jamais de faits."},
            {"role": "user", "content": prompt}
        ],
        "stream": False,
        "options": {"temperature": 0.4, "num_predict": 280}
    }

    try:
        r = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=120)
        r.raise_for_status()
        return (r.json().get("message", {}) or {}).get("content", "").strip() or "‚Äî"
    except Exception as e:
        # Fallback si le LLM plante : on renvoie une version simple bas√©e sur les facts
        lines = ["Je te propose :"]
        for i, item in enumerate(recos_payload[:5], start=1):
            lines.append(f"{i}. {item['title']} ({item['year']}) ‚Äî {item['score']}/10")
            why_clean = (item.get("why") or "").replace("\n", " | ")
            lines.append(f"   {why_clean}")
        lines.append(f"(LLM indisponible: {e})")
        return "\n".join(lines)


# ===============================
# UI
# ===============================
st.set_page_config(page_title="Reco Vid√©oth√®que", layout="wide")
st.title("üé¨ Recommandations personnalis√©es (MVP PostgreSQL + R√©alisateur)")

st.subheader("üí¨ Assistant cin√©ma")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "assistant",
            "content": (
                "Dis-moi ce que tu as envie de regarder.\n\n"
                "Exemples :\n"
                "- un thriller tendu, pas trop long\n"
                "- un film r√©cent et bien not√©\n"
                "- quelque chose dans le style de Villeneuve\n\n"
                "Je recommande uniquement parmi les films de ta vid√©oth√®que."
            )
        }
    ]

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
user_id = DEFAULT_USER_ID  # tout par le chat, on garde 1 user_id fixe
genre_profile_df, candidates, genre_profile, genre_names, film_genres, film_directors, director_profile, director_profile_df = load_data(user_id)

available_genres = sorted(list(genre_names.values()))
genre_id_by_name = {name: gid for gid, name in genre_names.items()}

user_text = st.chat_input("D√©cris ton envie cin√©ma‚Ä¶")

if user_text:
    st.session_state["messages"].append({"role": "user", "content": user_text})
    with st.chat_message("user"):
        st.markdown(user_text)

    with st.spinner("Je cherche dans ta vid√©oth√®que‚Ä¶"):
        filters = llm_extract_filters(user_text, available_genres)
        top_k = int(filters.get("top_k", 10))
        max_runtime = filters.get("max_runtime")

        filtered_candidates = apply_filters(
            candidates=candidates,
            film_genres=film_genres,
            film_directors=film_directors,
            filters=filters,
            genre_id_by_name=genre_id_by_name
        )

        recos_df = recommend(
            candidates=filtered_candidates,
            film_genres=film_genres,
            genre_profile=genre_profile,
            genre_names=genre_names,
            film_directors=film_directors,
            director_profile=director_profile,
            max_runtime=max_runtime or 10**9,
            top_k=top_k
        )

        answer = "Je n‚Äôai rien trouv√©, essaie d‚Äô√©largir un peu." if recos_df.empty else llm_format_answer(user_text, recos_df.head(5))

    st.session_state["messages"].append({"role": "assistant", "content": answer})
    with st.chat_message("assistant"):
        st.markdown(answer)

    with st.expander("üîç Voir les recommandations calcul√©es"):
        st.dataframe(recos_df, use_container_width=True)



with st.sidebar:
    st.header("Param√®tres")
    user_id = st.number_input("Utilisateur (user_id)", value=DEFAULT_USER_ID, step=1)
    top_k = st.slider("Nombre de recommandations", 5, 30, 10)
    max_runtime = st.slider("Dur√©e max (minutes)", 60, 240, 120)
    use_llm = st.checkbox("Am√©liorer l'explication (Ollama)", value=False)
    ollama_model = st.text_input("Mod√®le Ollama", value="llama3.1:8b")
    go = st.button("üéØ G√©n√©rer")

# if go:
#     with st.spinner("Chargement et calcul..."):
#         conn = get_conn()

#         genre_profile_df = fetch_df(conn, SQL_GENRE_PROFILE, {"user_id": user_id})
#         if genre_profile_df.empty:
#             conn.close()
#             st.error("Pas assez de films not√©s pour construire un profil de genres.")
#             st.stop()

#         candidates = fetch_df(conn, SQL_CANDIDATES, {"user_id": user_id})
#         film_genres_df = fetch_df(conn, SQL_FILM_GENRES)
#         genres_df = fetch_df(conn, SQL_GENRES)

#         # Directors (peut √©chouer si sch√©ma film_credit diff√©rent)
#         film_directors_df = fetch_df(conn, SQL_FILM_DIRECTORS)
#         director_profile_df = fetch_df(conn, SQL_DIRECTOR_PROFILE, {"user_id": user_id})

#         conn.close()

#     # Maps
#     genre_profile = {int(k): float(v) for k, v in zip(genre_profile_df.genre_id, genre_profile_df.avg_rating)}
#     genre_names = dict(zip(genres_df.genre_id, genres_df.name))
#     film_genres = film_genres_df.groupby("film_id")["genre_id"].apply(list).to_dict()

#     film_directors = {}
#     if not film_directors_df.empty:
#         film_directors = dict(zip(film_directors_df["film_id"], film_directors_df["directors"]))

#     director_profile = {}
#     if not director_profile_df.empty:
#         director_profile = {
#             row["director_name"]: (float(row["avg_rating"]), int(row["n"]))
#             for _, row in director_profile_df.iterrows()
#         }

#     results = recommend(
#         candidates=candidates,
#         film_genres=film_genres,
#         genre_profile=genre_profile,
#         genre_names=genre_names,
#         film_directors=film_directors,
#         director_profile=director_profile,
#         max_runtime=max_runtime,
#         top_k=top_k
#     )

#     st.caption(f"DEBUG raw score range: {results['score'].min()} .. {results['score'].max()}")

#     st.subheader("üé• Recommandations")
#     if results.empty:
#         st.warning("Aucun r√©sultat (peut-√™tre trop de filtres, ou peu de films candidats).")
#     else:
#         # Affichage fa√ßon "cards"
#         for i, r in enumerate(results.itertuples(index=False), start=1):
#             st.markdown(f"### {i}. {r.title} ({r.year}) ‚Äî **{r.score}/10**")
#             rt = f"{r.runtime} min" if r.runtime else "inconnue"
#             st.caption(f"Dur√©e : {rt}")
#             st.markdown(r.why)
#             if use_llm:
#                 narrative = ollama_rewrite(
#                     model=ollama_model,
#                     title=r.title,
#                     year=r.year,
#                     score=float(r.score),
#                     why=r.why
#                 )
#                 st.markdown(f"> {narrative}")
#             st.divider()

#     with st.expander("Voir le profil (genres)"):
#         prof = (
#             genre_profile_df
#             .merge(genres_df, on="genre_id")
#             .sort_values("avg_rating", ascending=False)
#         )
#         st.dataframe(prof, use_container_width=True)

#     with st.expander("Voir le profil (r√©alisateurs)"):
#         if director_profile_df.empty:
#             st.info("Profil r√©alisateur vide (pas assez de films not√©s par r√©alisateur, ou sch√©ma film_credit √† adapter).")
#         else:
#             st.dataframe(director_profile_df, use_container_width=True)
